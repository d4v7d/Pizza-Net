{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1wuMcAktNEXx",
        "-RlyWLwmIznT",
        "N16Cb275NLnw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importamos las dependencias y librerias"
      ],
      "metadata": {
        "id": "1wuMcAktNEXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJAggNYd_1us",
        "outputId": "c4655302-7b72-4bfb-d574-a2b7eef04d3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "metadata": {
        "id": "CULvNIMFKlc5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparamos los datos y los parametros"
      ],
      "metadata": {
        "id": "-RlyWLwmIznT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/datasets/pizza_not_pizza\"\n",
        "\n",
        "# Parámetros básicos\n",
        "batch_size = 32\n",
        "img_size = 180  # Ancho y alto de las imágenes\n",
        "num_epochs = 10\n",
        "validation_split = 0.2\n",
        "random_seed = 123\n"
      ],
      "metadata": {
        "id": "6w7_YwOcKqtZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Valores típicos para imágenes RGB\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Cargar el dataset completo usando ImageFolder\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "# División del dataset en entrenamiento y validación\n",
        "total_size = len(dataset)\n",
        "val_size = int(total_size * validation_split)\n",
        "train_size = total_size - val_size\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Crear DataLoaders para entrenamiento y validación\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "7OZXf_HYK1CE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a75efc-8043-4561-e003-aa149133d48a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo"
      ],
      "metadata": {
        "id": "N16Cb275NLnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir un modelo CNN simple\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # Reducción a la mitad\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # Reducción a la cuarta parte\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)   # Reducción a la octava parte\n",
        "        )\n",
        "        # Calcular el tamaño de la característica tras las capas convolucionales\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * (img_size // 8) * (img_size // 8), 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Configurar dispositivo: GPU si está disponible, de lo contrario CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN(num_classes=2).to(device)\n",
        "\n",
        "# Función de pérdida y optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "elovRNf-HPQv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función de entrenamiento"
      ],
      "metadata": {
        "id": "sEMU6jMtN7cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Entrenamiento\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / train_size\n",
        "        epoch_acc = running_corrects.double() / train_size\n",
        "\n",
        "        # Evaluación en el conjunto de validación\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_loss = val_loss / val_size\n",
        "        val_acc = val_corrects.double() / val_size\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "_w2z8NgLN-lo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciar el entrenamiento del modelo\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT95yEJzOJ9P",
        "outputId": "b62bf39b-0f95-4207-dcf2-3cf2ef562d06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Loss: 0.6436, Train Acc: 0.6529 - Val Loss: 0.5496, Val Acc: 0.7379\n",
            "Epoch 2/10 - Train Loss: 0.5826, Train Acc: 0.7025 - Val Loss: 0.5640, Val Acc: 0.7023\n",
            "Epoch 3/10 - Train Loss: 0.5026, Train Acc: 0.7661 - Val Loss: 0.5197, Val Acc: 0.7481\n",
            "Epoch 4/10 - Train Loss: 0.4619, Train Acc: 0.7921 - Val Loss: 0.4973, Val Acc: 0.7583\n",
            "Epoch 5/10 - Train Loss: 0.3393, Train Acc: 0.8576 - Val Loss: 0.4851, Val Acc: 0.7837\n",
            "Epoch 6/10 - Train Loss: 0.2255, Train Acc: 0.8989 - Val Loss: 0.5512, Val Acc: 0.7837\n",
            "Epoch 7/10 - Train Loss: 0.1183, Train Acc: 0.9593 - Val Loss: 0.6481, Val Acc: 0.7761\n",
            "Epoch 8/10 - Train Loss: 0.0606, Train Acc: 0.9797 - Val Loss: 0.8281, Val Acc: 0.7837\n",
            "Epoch 9/10 - Train Loss: 0.0290, Train Acc: 0.9930 - Val Loss: 0.8308, Val Acc: 0.7710\n",
            "Epoch 10/10 - Train Loss: 0.0240, Train Acc: 0.9917 - Val Loss: 1.4826, Val Acc: 0.7328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación"
      ],
      "metadata": {
        "id": "9XmNXSUpRxLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def test_model(model, val_dataset, num_images=25):\n",
        "    model.eval()\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Obtener índices aleatorios de imágenes\n",
        "    random_indices = random.sample(range(len(val_dataset)), num_images)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, index in enumerate(random_indices):\n",
        "            # Obtener la imagen y la etiqueta usando el índice aleatorio\n",
        "            image, label = val_dataset[index]\n",
        "\n",
        "            # Preparar la imagen y moverla al dispositivo correspondiente\n",
        "            image = image.unsqueeze(0).to(device)\n",
        "            label = torch.tensor([label]).to(device)\n",
        "\n",
        "            outputs = model(image)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            ax = plt.subplot(5, 5, i + 1)  # Organiza las imágenes en una cuadrícula 5x5\n",
        "            ax.axis('off')\n",
        "            ax.set_title(f'Predicted: {dataset.classes[preds[0]]}\\nActual: {dataset.classes[label.item()]}', fontsize=8)\n",
        "\n",
        "            # Mover la imagen a CPU para mostrarla\n",
        "            image = image.cpu().squeeze().numpy().transpose((1, 2, 0))\n",
        "            # Desnormalizar para mostrar correctamente\n",
        "            image = (image * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n",
        "            image = np.clip(image, 0, 1)\n",
        "\n",
        "            ax.imshow(image)\n",
        "\n",
        "    # Ajustar el espacio entre subplots para evitar solapamientos\n",
        "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
        "\n",
        "# Uso del val_dataset como test_loader (idealmente se debería tener un conjunto de test separado)\n",
        "test_model(model, val_dataset)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "rgIzw1oXWMND",
        "outputId": "bf80a4d2-a0c7-4324-ca9a-e2762d8e1144"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c2e8db722349>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Uso del val_dataset como test_loader (idealmente se debería tener un conjunto de test separado)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}